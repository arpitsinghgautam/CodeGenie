{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install e2b_code_interpreter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbctEeu2ocZG",
        "outputId": "e228cdb7-5f48-4ff0-c177-79ad06b43735"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting e2b_code_interpreter\n",
            "  Downloading e2b_code_interpreter-0.0.3-py3-none-any.whl (10.0 kB)\n",
            "Collecting e2b>=0.14.11 (from e2b_code_interpreter)\n",
            "  Downloading e2b-0.14.13-py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.2/100.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>1 in /usr/local/lib/python3.10/dist-packages (from e2b_code_interpreter) (2.6.4)\n",
            "Requirement already satisfied: websocket-client<2.0.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from e2b_code_interpreter) (1.7.0)\n",
            "Collecting aenum>=3.1.11 (from e2b>=0.14.11->e2b_code_interpreter)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.10/dist-packages (from e2b>=0.14.11->e2b_code_interpreter) (3.9.3)\n",
            "Collecting jsonrpcclient>=4.0.3 (from e2b>=0.14.11->e2b_code_interpreter)\n",
            "  Downloading jsonrpcclient-4.0.3-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from e2b>=0.14.11->e2b_code_interpreter) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from e2b>=0.14.11->e2b_code_interpreter) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from e2b>=0.14.11->e2b_code_interpreter) (4.11.0)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from e2b>=0.14.11->e2b_code_interpreter) (2.0.7)\n",
            "Collecting websockets>=11.0.3 (from e2b>=0.14.11->e2b_code_interpreter)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>1->e2b_code_interpreter) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>1->e2b_code_interpreter) (2.16.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->e2b>=0.14.11->e2b_code_interpreter) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->e2b>=0.14.11->e2b_code_interpreter) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->e2b>=0.14.11->e2b_code_interpreter) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->e2b>=0.14.11->e2b_code_interpreter) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->e2b>=0.14.11->e2b_code_interpreter) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->e2b>=0.14.11->e2b_code_interpreter) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->e2b>=0.14.11->e2b_code_interpreter) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->e2b>=0.14.11->e2b_code_interpreter) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->e2b>=0.14.11->e2b_code_interpreter) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->e2b>=0.14.11->e2b_code_interpreter) (2024.2.2)\n",
            "Installing collected packages: aenum, websockets, jsonrpcclient, e2b, e2b_code_interpreter\n",
            "Successfully installed aenum-3.1.15 e2b-0.14.13 e2b_code_interpreter-0.0.3 jsonrpcclient-4.0.3 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xHWegMPvoIM_"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from e2b_code_interpreter import CodeInterpreter\n",
        "# from constants import E2B_API_KEY, GEMINI_API_KEY\n",
        "\n",
        "E2B_API_KEY=\"e2b_d04acfcdc6b62e4cf7a623f81689feabd9345dfe\"\n",
        "GEMINI_API_KEY = \"AIzaSyAdATJYq_TqgvOMQKMdkGgweaWH9MXRGfs\"\n",
        "#GEMINI SETUP\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# Set up the model\n",
        "generation_config = {\n",
        "  \"temperature\": 0.9,\n",
        "  \"top_p\": 1,\n",
        "  \"top_k\": 1,\n",
        "  \"max_output_tokens\": 2048,\n",
        "}\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
        "                              generation_config=generation_config)\n",
        "\n",
        "convo = model.start_chat(history=[\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def user_in():\n",
        "  # Get user input or prompt for Gemini\n",
        "  user_input = input(\"Enter your Problem: \")\n",
        "\n",
        "  # Send the prompt to Gemini and get the generated code\n",
        "  convo.send_message(user_input+ \"Give the complete code along with the driver code and test cases\")\n",
        "  generated_code = convo.last.text\n",
        "  # print(\"Generated Code: \",generated_code)\n",
        "  return generated_code"
      ],
      "metadata": {
        "id": "7WH0qWkho3c6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_gemini_output(generated_code):\n",
        "  # Finding the start and end indices of test code and output\n",
        "  code_start_index = generated_code.find(\"```python\") + len(\"```python\")\n",
        "  code_end_index = generated_code.find(\"```\", code_start_index)\n",
        "  # Extracting test code and output\n",
        "  code = generated_code[code_start_index:code_end_index].strip()\n",
        "  # print(code)\n",
        "  return code"
      ],
      "metadata": {
        "id": "O8ujOP75w7Ja"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def execute():\n",
        "  generated_code = user_in()\n",
        "  code = clean_gemini_output(generated_code)\n",
        "\n",
        "  while True:\n",
        "    # Create an instance of the CodeInterpreter\n",
        "    with CodeInterpreter(api_key=E2B_API_KEY) as sandbox:\n",
        "        try:\n",
        "            # Execute the generated code\n",
        "            execution = sandbox.notebook.exec_cell(code)\n",
        "            print(execution)\n",
        "            convo.send_message(f\"result when executing the given code; {execution} IF THE Logs output MATCHES THE vaild test cases without any errors in the error Return YES else return NO; ONLY RETURN ONE WORD ANSWER 'YES' if correct and return 'NO' along with the problem if the output is wrong or Error is their\")\n",
        "            code_double_check = convo.last.text\n",
        "            print(code_double_check)\n",
        "            if code_double_check == \"YES\":\n",
        "              print(\"Double Check successful; Code is Correct\")\n",
        "              # Save the code to a file if it runs successfully\n",
        "              with open(\"generated_code.py\", \"a\") as f:\n",
        "                  f.write(code)\n",
        "              print(\"Code executed successfully!\")\n",
        "              break\n",
        "            else:\n",
        "              convo.send_message(f\"Check whats the issue and Fix the Code: {code_double_check} ONLY REUTURN THE NEW COMPLETE CODE with the test cases\")\n",
        "              code = clean_gemini_output\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            # Send the error traceback to Gemini\n",
        "            error_traceback = str(e)\n",
        "            convo.send_message(f\"Error: {error_traceback} Correct the code and Send again\")\n",
        "            print(f\"Error: {error_traceback}\")\n",
        ""
      ],
      "metadata": {
        "id": "gD8K21UJo3YL"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "execute()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "cgfqOYLh3oD_",
        "outputId": "3accec88-ff8e-4f3b-957c-35a9450c54a1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Problem: Generate Palindrome word python code\n",
            "results=[] logs=Logs(stdout=['racecar is a palindrome: True\\nkayak is a palindrome: True\\nstressed is a palindrome: False\\npalindrome is a palindrome: False\\nhello is a palindrome: False\\n'], stderr=[]) error=None\n",
            "YES\n",
            "Double Check successful; Code is Correct\n",
            "Code executed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epyTI3GkATls",
        "outputId": "07229161-8c95-4d78-bf88-1cc82efe8af6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.33.0-py2.py3-none-any.whl (8.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.0)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.11.0)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.33.0 watchdog-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit-chat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZQXbunfBZXU",
        "outputId": "77b6a7ea-28f2-4f89-8a07-237cd69b20d8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit-chat\n",
            "  Downloading streamlit_chat-0.1.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.10/dist-packages (from streamlit-chat) (1.33.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=0.63->streamlit-chat) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (24.0)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (4.11.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (6.3.3)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-chat) (4.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-chat) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->streamlit-chat) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->streamlit-chat) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->streamlit-chat) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-chat) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-chat) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-chat) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-chat) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit-chat) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit-chat) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-chat) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-chat) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.63->streamlit-chat) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit>=0.63->streamlit-chat) (1.16.0)\n",
            "Installing collected packages: streamlit-chat\n",
            "Successfully installed streamlit-chat-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from google.generativeai import genai\n",
        "from e2b_code_interpreter import CodeInterpreter\n",
        "\n",
        "# API KEYS\n",
        "E2B_API_KEY=\"e2b_d04acfcdc6b62e4cf7a623f81689feabd9345dfe\"\n",
        "GEMINI_API_KEY = \"AIzaSyAdATJYq_TqgvOMQKMdkGgweaWH9MXRGfs\"\n",
        "\n",
        "#GEMINI SETUP\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# Set up the model\n",
        "generation_config = {\n",
        "  \"temperature\": 0.9,\n",
        "  \"top_p\": 1,\n",
        "  \"top_k\": 1,\n",
        "  \"max_output_tokens\": 2048,\n",
        "}\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
        "                              generation_config=generation_config)\n",
        "\n",
        "convo = model.start_chat(history=[\n",
        "])\n",
        "\n",
        "# Function to get user input\n",
        "def user_in():\n",
        "  # Get user input or prompt for Gemini\n",
        "  user_input = input(\"Enter your Problem: \")\n",
        "\n",
        "  # Send the prompt to Gemini and get the generated code\n",
        "  convo.send_message(user_input+ \"Give the complete code along with the driver code and test cases\")\n",
        "  generated_code = convo.last.text\n",
        "  # print(\"Generated Code: \",generated_code)\n",
        "  return generated_code\n",
        "\n",
        "# Function to clean Gemini output\n",
        "def clean_gemini_output(generated_code):\n",
        "  # Finding the start and end indices of test code and output\n",
        "  code_start_index = generated_code.find(\"```python\") + len(\"```python\")\n",
        "  code_end_index = generated_code.find(\"```\", code_start_index)\n",
        "  # Extracting test code and output\n",
        "  code = generated_code[code_start_index:code_end_index].strip()\n",
        "  # print(code)\n",
        "  return code\n",
        "\n",
        "# Main function to execute code\n",
        "def execute():\n",
        "  generated_code = user_in()\n",
        "  code = clean_gemini_output(generated_code)\n",
        "\n",
        "  while True:\n",
        "    # Create an instance of the CodeInterpreter\n",
        "    with CodeInterpreter(api_key=E2B_API_KEY) as sandbox:\n",
        "        try:\n",
        "            # Execute the generated code\n",
        "            execution = sandbox.notebook.exec_cell(code)\n",
        "            print(execution)\n",
        "            convo.send_message(f\"result when executing the given code; {execution} IF THE Logs output MATCHES THE vaild test cases without any errors in the error Return YES else return NO; ONLY RETURN ONE WORD ANSWER 'YES' if correct and return 'NO' along with the problem if the output is wrong or Error is their\")\n",
        "            code_double_check = convo.last.text\n",
        "            print(code_double_check)\n",
        "            if code_double_check == \"YES\":\n",
        "              print(\"Double Check successful; Code is Correct\")\n",
        "              # Save the code to a file if it runs successfully\n",
        "              with open(\"generated_code.py\", \"a\") as f:\n",
        "                  f.write(code)\n",
        "              print(\"Code executed successfully!\")\n",
        "              break\n",
        "            else:\n",
        "              convo.send_message(f\"Check whats the issue and Fix the Code: {code_double_check} ONLY REUTURN THE NEW COMPLETE CODE with the test cases\")\n",
        "              code = clean_gemini_output\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            # Send the error traceback to Gemini\n",
        "            error_traceback = str(e)\n",
        "            convo.send_message(f\"Error: {error_traceback} Correct the code and Send again\")\n",
        "            print(f\"Error: {error_traceback}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lW5SFYzvAVOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import google.generativeai as genai\n",
        "import time\n",
        "import random\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Chat with Gemini Pro\",\n",
        "    page_icon=\"🔥\"\n",
        ")\n",
        "\n",
        "st.title(\"Chat with Gemini Pro\")\n",
        "st.caption(\"A Chatbot Powered by Google Gemini Pro\")\n",
        "\n",
        "if \"app_key\" not in st.session_state:\n",
        "    app_key = st.text_input(\"Please enter your Gemini API Key\", type='password')\n",
        "    if app_key:\n",
        "        st.session_state.app_key = app_key\n",
        "\n",
        "if \"history\" not in st.session_state:\n",
        "    st.session_state.history = []\n",
        "\n",
        "try:\n",
        "    genai.configure(api_key = st.session_state.app_key)\n",
        "except AttributeError as e:\n",
        "    st.warning(\"Please Put Your Gemini API Key First\")\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-pro\")\n",
        "chat = model.start_chat(history = st.session_state.history)\n",
        "\n",
        "with st.sidebar:\n",
        "    if st.button(\"Clear Chat Window\", use_container_width=True, type=\"primary\"):\n",
        "        st.session_state.history = []\n",
        "        st.rerun()\n",
        "\n",
        "for message in chat.history:\n",
        "    role =\"assistant\" if message.role == 'model' else message.role\n",
        "    with st.chat_message(role):\n",
        "        st.markdown(message.parts[0].text)\n",
        "\n",
        "if \"app_key\" in st.session_state:\n",
        "    if prompt := st.chat_input(\"\"):\n",
        "        prompt = prompt.replace('\\n', ' \\n')\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.markdown(prompt)\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            message_placeholder = st.empty()\n",
        "            message_placeholder.markdown(\"Thinking...\")\n",
        "            try:\n",
        "                full_response = \"\"\n",
        "                for chunk in chat.send_message(prompt, stream=True):\n",
        "                    word_count = 0\n",
        "                    random_int = random.randint(5,10)\n",
        "                    for word in chunk.text:\n",
        "                        full_response+=word\n",
        "                        word_count+=1\n",
        "                        if word_count == random_int:\n",
        "                            time.sleep(0.05)\n",
        "                            message_placeholder.markdown(full_response + \"_\")\n",
        "                            word_count = 0\n",
        "                            random_int = random.randint(5,10)\n",
        "                message_placeholder.markdown(full_response)\n",
        "            except genai.types.generation_types.BlockedPromptException as e:\n",
        "                st.exception(e)\n",
        "            except Exception as e:\n",
        "                st.exception(e)\n",
        "            st.session_state.history = chat.history\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbQePEjgBYA8",
        "outputId": "f580c457-5f39-4ded-d472-f71255755e84"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app2.py\n",
        "import streamlit as st\n",
        "import google.generativeai as genai\n",
        "import time\n",
        "import random\n",
        "from e2b_code_interpreter import CodeInterpreter\n",
        "import os\n",
        "\n",
        "# Function to clean Gemini output\n",
        "def clean_gemini_output(generated_code):\n",
        "    code_start_index = generated_code.find(\"```python\") + len(\"```python\")\n",
        "    code_end_index = generated_code.find(\"```\", code_start_index)\n",
        "    code = generated_code[code_start_index:code_end_index].strip()\n",
        "    return code\n",
        "\n",
        "# Main function to execute code\n",
        "def execute_code(code):\n",
        "    with CodeInterpreter(api_key=os.environ.get(\"E2B_API_KEY\")) as sandbox:\n",
        "        try:\n",
        "            execution = sandbox.notebook.exec_cell(code)\n",
        "            st.write(\"Inside execute_function\")\n",
        "            st.code(execution.output, language=\"python\")\n",
        "            return execution.output\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error: {str(e)}\")\n",
        "            return str(e)\n",
        "\n",
        "st.set_page_config(page_title=\"CodeGenie\", page_icon=\"💻\")\n",
        "st.title(\"CodeGenie\")\n",
        "st.caption(\"Your AI Coding Assistant Chatbot Powered by E2B Code Interpreter SDK\")\n",
        "\n",
        "if \"app_key\" not in st.session_state:\n",
        "    app_key = st.text_input(\"Please enter your Gemini API Key\", type='password')\n",
        "    if app_key:\n",
        "        st.session_state.app_key = app_key\n",
        "\n",
        "if \"history\" not in st.session_state:\n",
        "    st.session_state.history = []\n",
        "\n",
        "try:\n",
        "    genai.configure(api_key=st.session_state.app_key)\n",
        "except AttributeError as e:\n",
        "    st.warning(\"Please Put Your Gemini API Key First\")\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-pro\")\n",
        "chat = model.start_chat(history=st.session_state.history)\n",
        "\n",
        "with st.sidebar:\n",
        "    if st.button(\"Clear Chat Window\", use_container_width=True, type=\"primary\"):\n",
        "        st.session_state.history = []\n",
        "        st.rerun()\n",
        "\n",
        "for message in chat.history:\n",
        "    role = \"assistant\" if message.role == 'model' else message.role\n",
        "    with st.chat_message(role):\n",
        "        st.markdown(message.parts[0].text)\n",
        "\n",
        "if \"app_key\" in st.session_state:\n",
        "    if prompt := st.chat_input(\"\"):\n",
        "        prompt = prompt.replace('\\n', ' \\n')\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.markdown(prompt)\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            message_placeholder = st.empty()\n",
        "            message_placeholder.markdown(\"Thinking...\")\n",
        "            try:\n",
        "                full_response = \"\"\n",
        "                for chunk in chat.send_message(prompt, stream=True):\n",
        "                    word_count = 0\n",
        "                    random_int = random.randint(5, 10)\n",
        "                    for word in chunk.text:\n",
        "                        full_response += word\n",
        "                        word_count += 1\n",
        "                        if word_count == random_int:\n",
        "                            time.sleep(0.05)\n",
        "                            message_placeholder.markdown(full_response + \"_\")\n",
        "                            word_count = 0\n",
        "                            random_int = random.randint(5, 10)\n",
        "                    message_placeholder.markdown(full_response)\n",
        "            except genai.types.generation_types.BlockedPromptException as e:\n",
        "                st.exception(e)\n",
        "            except Exception as e:\n",
        "                st.exception(e)\n",
        "            st.session_state.history = chat.history\n",
        "\n",
        "        if \"```python\" in full_response:\n",
        "          code = clean_gemini_output(full_response)\n",
        "\n",
        "          if \"executed_code\" not in st.session_state:\n",
        "            st.session_state.executed_code = False\n",
        "\n",
        "          if \"downloaded_code\" not in st.session_state:\n",
        "            st.session_state.downloaded_code = False\n",
        "\n",
        "          col1, col2 = st.columns(2)\n",
        "          with col1:\n",
        "              execute_button_clicked = st.button(\"Execute Code\")\n",
        "              if execute_button_clicked:\n",
        "                  output = execute_code(code)\n",
        "                  st.code(code, language=\"python\")  # Display the code\n",
        "                  st.write(output)  # Display the output using st.write\n",
        "                  st.session_state.executed_code = True\n",
        "\n",
        "          with col2:\n",
        "              download_button_clicked = st.button(\"Download Code\")\n",
        "              if download_button_clicked:\n",
        "                  with open(\"generated_code.py\", \"w\") as f:\n",
        "                      f.write(code)\n",
        "                  # Send the file for download\n",
        "                  st.download_button(\n",
        "                      label=\"Download Code\",\n",
        "                      data=code,\n",
        "                      file_name=\"generated_code.py\",\n",
        "                      mime=\"text/plain\",\n",
        "                  )\n",
        "                  st.session_state.downloaded_code = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fI5oPliPJRL",
        "outputId": "5ad0fb2d-cd27-4cc8-c8aa-c3f84330fb6d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpGmiBJaDNhk",
        "outputId": "3ce3fde9-cde8-4fae-d5ad-b87aef0124b4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors and audited 22 packages in 1.694s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 1 \u001b[93mmoderate\u001b[0m severity vulnerability\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/app2.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "SXS7hR5BIlc_"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-ZWIjHjIwQ2",
        "outputId": "a80b23fd-cc13-45d4-d414-3ce0e52efc69"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 1.672s\n",
            "your url is: https://crazy-rocks-listen.loca.lt\n",
            "/root/.npm/_npx/35326/lib/node_modules/localtunnel/bin/lt.js:81\n",
            "    throw err;\n",
            "    ^\n",
            "\n",
            "Error: connection refused: localtunnel.me:41167 (check your firewall settings)\n",
            "    at Socket.<anonymous> (/root/.npm/_npx/35326/lib/node_modules/\u001b[4mlocaltunnel\u001b[24m/lib/TunnelCluster.js:52:11)\n",
            "\u001b[90m    at Socket.emit (events.js:315:20)\u001b[39m\n",
            "\u001b[90m    at emitErrorNT (internal/streams/destroy.js:106:8)\u001b[39m\n",
            "\u001b[90m    at emitErrorCloseNT (internal/streams/destroy.js:74:3)\u001b[39m\n",
            "\u001b[90m    at processTicksAndRejections (internal/process/task_queues.js:80:21)\u001b[39m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_SkC1xDlIyso"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}